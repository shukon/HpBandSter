{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nExample 4 - on the cluster\n==========================\n\nThis example shows how to run HpBandster in a cluster environment.\nThe actual python code does differ substantially from example 3, except for a\nshared directory that is used to communicate the location of the nameserver to\nevery worker, and the fact that the communication is done over the network instead\nof just the loop back interface.\n\n\nTo actually run it as a batch job, usually a shell script is required.\nThose differer slightly from scheduler to scheduler.\nHere we provide an example script for the Sun Grid Engine (SGE), but adapting that to\nany other scheduler should be easy.\nThe script simply specifies the logging files for output (`-o`) and error `-e`),\nloads a virtual environment, and then executes the master for the first array task\nand a worker otherwise.\nArray jobs execute the same source multiple times and are bundled together into one job,\nwhere each task gets a unique task ID.\nFor SGE those IDs are positive integers and we simply say the first task is the master.\n\n\n.. code-block:: bash\n\n   # submit via qsub -t 1-4 -q test_core.q example_4_cluster_submit_me.sh\n\n   #$ -cwd\n   #$ -o $JOB_ID-$TASK_ID.o\n   #$ -e $JOB_ID-$TASK_ID.e\n\n   # enter the virtual environment\n   source ~sfalkner/virtualenvs/HpBandSter_tests/bin/activate\n\n\n   if [ $SGE_TASK_ID -eq 1]\n      then python3 example_4_cluster.py --run_id $JOB_ID --nic_name eth0 --working_dir .\n   else \n      python3 example_4_cluster.py --run_id $JOB_ID --nic_name eth0  --working_dir . --worker\n   fi\n\nYou can simply copy the above code into a file, say submit_me.sh, and tell SGE to run it via:\n\n.. code-block:: bash\n\n   qsub -t 1-4 -q your_queue_name submit_me.sh\n\n\nNow to the actual python source:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import logging\nlogging.basicConfig(level=logging.INFO)\n\nimport argparse\nimport pickle\nimport time\n\nimport hpbandster.core.nameserver as hpns\nimport hpbandster.core.result as hpres\n\nfrom hpbandster.optimizers import BOHB as BOHB\nfrom hpbandster.examples.commons import MyWorker\n\n\n\nparser = argparse.ArgumentParser(description='Example 1 - sequential and local execution.')\nparser.add_argument('--min_budget',   type=float, help='Minimum budget used during the optimization.',    default=9)\nparser.add_argument('--max_budget',   type=float, help='Maximum budget used during the optimization.',    default=243)\nparser.add_argument('--n_iterations', type=int,   help='Number of iterations performed by the optimizer', default=4)\nparser.add_argument('--n_workers', type=int,   help='Number of workers to run in parallel.', default=2)\nparser.add_argument('--worker', help='Flag to turn this into a worker process', action='store_true')\nparser.add_argument('--run_id', type=str, help='A unique run id for this optimization run. An easy option is to use the job id of the clusters scheduler.')\nparser.add_argument('--nic_name',type=str, help='Which network interface to use for communication.')\nparser.add_argument('--shared_directory',type=str, help='A directory that is accessible for all processes, e.g. a NFS share.')\n\n\nargs=parser.parse_args()\n\n# Every process has to lookup the hostname\nhost = hpns.nic_name_to_host(args.nic_name)\n\n\nif args.worker:\n\ttime.sleep(5)\t# short artificial delay to make sure the nameserver is already running\n\tw = MyWorker(sleep_interval = 0.5,run_id=args.run_id, host=host)\n\tw.load_nameserver_credentials(working_directory=args.shared_directory)\n\tw.run(background=False)\n\texit(0)\n\n# Start a nameserver:\n# We now start the nameserver with the host name from above and a random open port (by setting the port to 0)\nNS = hpns.NameServer(run_id=args.run_id, host=host, port=0, working_directory=args.shared_directory)\nns_host, ns_port = NS.start()\n\n# Most optimizers are so computationally inexpensive that we can affort to run a\n# worker in parallel to it. Note that this one has to run in the background to\n# not plock!\nw = MyWorker(sleep_interval = 0.5,run_id=args.run_id, host=host, nameserver=ns_host, nameserver_port=ns_port)\nw.run(background=True)\n\n# Run an optimizer\n# We now have to specify the host, and the nameserver information\nbohb = BOHB(  configspace = MyWorker.get_configspace(),\n\t\t\t  run_id = args.run_id,\n\t\t\t  host=host,\n\t\t\t  nameserver=ns_host,\n\t\t\t  nameserver_port=ns_port,\n\t\t\t  min_budget=args.min_budget, max_budget=args.max_budget\n\t\t   )\nres = bohb.run(n_iterations=args.n_iterations, min_n_workers=args.n_workers)\n\n\n# In a cluster environment, you usually want to store the results for later analysis.\n# One option is to simply pickle the Result object \nwith open(os.path.join(args.shared_directory, 'results.pkl'), 'wb') as fh:\n\tpickle.dump(res, fh)\n\n\n# Step 4: Shutdown\n# After the optimizer run, we must shutdown the master and the nameserver.\nbohb.shutdown(shutdown_workers=True)\nNS.shutdown()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}